# ğŸ« Vision-GPT2: Chest X-Ray Report Generation

GÃ¶ÄŸÃ¼s rÃ¶ntgeni gÃ¶rÃ¼ntÃ¼lerinden otomatik radyoloji raporu Ã¼retimi iÃ§in Vision-GPT2 tabanlÄ± derin Ã¶ÄŸrenme modeli.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#-genel-bakÄ±ÅŸ)
- [Model Mimarisi](#-model-mimarisi)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [EÄŸitim](#-eÄŸitim)
- [SonuÃ§lar](#-sonuÃ§lar)
- [Dosya YapÄ±sÄ±](#-dosya-yapÄ±sÄ±)

## ğŸ¯ Genel BakÄ±ÅŸ

Bu proje, gÃ¶ÄŸÃ¼s rÃ¶ntgenlerinden otomatik olarak **Findings** ve **Impression** bÃ¶lÃ¼mlerini iÃ§eren yapÄ±landÄ±rÄ±lmÄ±ÅŸ radyoloji raporlarÄ± Ã¼retebilen bir Vision-Language model iÃ§ermektedir.

### Ã–zellikler

- âœ… CNN tabanlÄ± gÃ¶rÃ¼ntÃ¼ kodlayÄ±cÄ± (DenseNet121)
- âœ… GPT-2 tabanlÄ± dil Ã§Ã¶zÃ¼cÃ¼
- âœ… Cross-attention mekanizmasÄ±
- âœ… Streamlit web arayÃ¼zÃ¼
- âœ… GerÃ§ek zamanlÄ± rapor Ã¼retimi

## ğŸ— Model Mimarisi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GÃ¶ÄŸÃ¼s RÃ¶ntgeni GÃ¶rÃ¼ntÃ¼sÃ¼                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GÃ¶rÃ¼ntÃ¼ Ã–n Ä°ÅŸleme (384x384, Normalize)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                CNN Encoder (DenseNet121)                     â”‚
â”‚                  GÃ¶rsel Ã–zellik Ã‡Ä±karÄ±mÄ±                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Cross-Attention Module                      â”‚
â”‚              (GÃ¶rsel â†” Metinsel Hizalama)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-2 Dil Ã‡Ã¶zÃ¼cÃ¼                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ãœretilen Radyoloji Raporu                       â”‚
â”‚              (Findings + Impression)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’» Kurulum

### Gereksinimler

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU iÃ§in)

### AdÄ±mlar

```bash
# 1. Repo'yu klonla
git clone https://github.com/CengizhanKARAGOZ/vision-gpt2-cxr-report.git
cd vision-gpt2-cxr-report

# 2. Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
.\venv\Scripts\activate  # Windows

# 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# 4. Model aÄŸÄ±rlÄ±klarÄ±nÄ± indir (eÄŸitilmiÅŸ model)
# weights/ klasÃ¶rÃ¼ne best_vgpt2.pt dosyasÄ±nÄ± koy
```

## ğŸš€ KullanÄ±m

### Streamlit Web ArayÃ¼zÃ¼

```bash
cd app
streamlit run streamlit_app.py
```

TarayÄ±cÄ±da `http://localhost:8501` adresine git.

### Python API

```python
from app.model_infer import load_model, build_transform, preprocess_pil
from PIL import Image

# Model yÃ¼kle
model, tokenizer = load_model("weights/best_vgpt2.pt", device="cpu")
transform = build_transform(img_size=384)

# GÃ¶rÃ¼ntÃ¼ yÃ¼kle ve iÅŸle
image = Image.open("xray.jpg")
x = preprocess_pil(image, transform)

# Rapor Ã¼ret
report = model.generate(
    x, tokenizer,
    prompt="Findings: The",
    max_new_tokens=100,
    temperature=0.70,
    repetition_penalty=1.20
)

print(report)
```

## ğŸ“ EÄŸitim

### Veri Seti

Model, [MIMIC-CXR](https://physionet.org/content/mimic-cxr/2.0.0/) veri seti Ã¼zerinde eÄŸitilmiÅŸtir.

- **EÄŸitim Ã¶rnekleri:** ~42,000
- **DoÄŸrulama Ã¶rnekleri:** ~313

### Kaggle'da EÄŸitim

```bash
# Kaggle notebook'ta Ã§alÄ±ÅŸtÄ±r
python train/train.py
```

### EÄŸitim Parametreleri

| Parametre | DeÄŸer |
|-----------|-------|
| Optimizer | AdamW |
| Learning Rate | 8e-5 |
| Weight Decay | 0.01 |
| Batch Size | 8 |
| Gradient Accumulation | 4 |
| Epochs | 4 |
| Image Size | 384x384 |
| Max Sequence Length | 256 |
| Label Smoothing | 0.1 |
| LR Schedule | Cosine Annealing |
| Mixed Precision | FP16 |

### EÄŸitim SonuÃ§larÄ±

| Epoch | Train Loss | Val Loss |
|-------|------------|----------|
| 1 | 2.0574 | 1.8070 |
| 2 | 1.7499 | 1.7235 |
| 3 | 1.6880 | 1.6975 |
| 4 | 1.6626 | 1.6854 |

## ğŸ“Š SonuÃ§lar

### Ã–rnek Ã‡Ä±ktÄ±lar

**Normal Bulgular:**
```
Findings: The lungs are clear without focal consolidation, pleural 
effusion, or pneumothorax. Heart and mediastinal silhouettes are normal.

Impression: No acute cardiopulmonary process.
```

**Patolojik Bulgular:**
```
Findings: There is increased opacity in the right lower lobe consistent 
with consolidation. Small right pleural effusion is noted.

Impression: Right lower lobe pneumonia with small pleural effusion.
```

### Model PerformansÄ±

- âœ… Normal vakalarda yÃ¼ksek tutarlÄ±lÄ±k
- âœ… Standart radyoloji terminolojisi kullanÄ±mÄ±
- âœ… Findings-Impression yapÄ±sal uyumu
- âš ï¸ Patolojik detaylarda sÄ±nÄ±rlÄ± spesifiklik

## ğŸ“ Dosya YapÄ±sÄ±

```
vision-gpt2-cxr-report/
â”œâ”€â”€ README.md                 
â”œâ”€â”€ requirements.txt          # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ train/
â”‚   â””â”€â”€ train.py             # EÄŸitim scripti
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ model_infer.py       # Model inference modÃ¼lÃ¼
â”‚   â””â”€â”€ streamlit_app.py     # Web arayÃ¼zÃ¼
â”œâ”€â”€ weights/
â”‚   â””â”€â”€ best_vgpt2.pt        # EÄŸitilmiÅŸ model (gitignore)
â””â”€â”€ examples/
    â””â”€â”€ sample_xray.jpg      # Ã–rnek gÃ¶rÃ¼ntÃ¼
```

## ğŸ“ Notlar

- Bu model **demo amaÃ§lÄ±dÄ±r**, klinik kullanÄ±m iÃ§in uygun deÄŸildir.
- Ãœretilen raporlar mutlaka uzman radyolog tarafÄ±ndan doÄŸrulanmalÄ±dÄ±r.
- Model, MIMIC-CXR veri setinin daÄŸÄ±lÄ±mÄ±na gÃ¶re eÄŸitilmiÅŸtir.

## ğŸ“„ Lisans

MIT License

## ğŸ™ TeÅŸekkÃ¼rler

- [MIMIC-CXR Dataset](https://physionet.org/content/mimic-cxr/2.0.0/)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [timm](https://github.com/huggingface/pytorch-image-models)

## ğŸ“š Referanslar

1. Irvin, J., et al. (2019). CheXpert: A large chest radiograph dataset.
2. Radford, A., et al. (2019). Language models are unsupervised multitask learners.
3. Chen, Z., et al. (2022). Generating radiology reports via memory-driven transformer.